{
  "hash": "40e29a9754d593e9c37be7b9ef532ba6",
  "result": {
    "markdown": "---\ntitle: Recipes for learning\ndate: '2018-02-18'\ncategories:\n  - dataviz\nimage: \"/posts/2018-02-18-recipes-for-learning/recipes-for-learning.png\"\ndescription: >\n  In this blogpost I introduce one of my favourite datasets, a treasure trove of 57,000+ recipes scraped from recipe websites for a fascinating research paper <a href='http://doi.org/10.1038/srep00196'>(DOI: 10.1038/srep00196)</a>  comparing how different cuisines choose ingredients. I first used this dataset in May 2015 to learn how to use R and continue to use it to test my understanding of new techniques and analysis. \n---\n\n\n\nI can accurately identify the day I started learning R properly as the 30th of April 2015. That's the day I was invited for an interview on the 26th of May at University of Oxford which had an interview exercise that required me to create a dummy 10 minute introduction to dataviz with a tool of my choice, using an **interesting dataset**. At the time, I knew Mathematica (and the Wolfram Language) incredibly well - but it was clear from the description of the task that the interviewers would massively prefer folks who knew R or Python.\n\nPython was clearly a mess of choices, I had to decide between Python 2.x or 3.x and there wasn't a self-contained solution for building web applications. Learning R and Shiny was the obvious choice in just over three weeks, as was the dataset I'd focus on.\n\n<div class='row'>\n\n<div class='col-sm-6'>\n\nOne of my absolute favourite datasets comes from a paper published in Nature, \"Flavor Network and the principles of food pairing\" (<a href=\"http://doi.org/10.1038/srep00196\" target=\"orcid.widget\" rel=\"noopener noreferrer\" style=\"vertical-align:top;\"><img src=\"/img/doi_16x16.png\" style=\"width:1em;margin-right:.2em;\" alt=\"GitHub icon\">doi:10.1038/srep00196</a>). The supplementary materials include two files:\n\n- srep00196-s2.csv: details the number of flavour compounds shared between over 1500 ingredients.\n- srep00196-s3.csv: contains over 57,000 recipes categorised by cuisine.\n\n</div>\n\n<div class='col-sm-6'>\n\n<center>\n<img src='2018-02-15_flavor-network-hairball.jpg' style='max-width:300px'/>\n</center>\n\n</div>\n\n</div>\n\nIn the paper the authors are interested examining whether different cuisines prefer recipes with highly similar or dissimilar tasting ingredients, amongst other things. I've embedded one of the highly beautified hair ball networks from the paper, and I definitey recommend reading this Open Access paper for some interesting observations about human cuisines. Now, it turned that out this was a fairly challenging dataset to first start learning R with, let's grab the data from Nature [^1] and have a look at why.\n\n::: {.cell}\n\n```{.r .cell-code}\n## Reproducibly download files to a temp location and unzip\nlibrary(\"tidyverse\")\nrecipes_data_dir <- tempdir()\ns2_zip <- tempfile(fileext = \".zip\")\ns3_zip <- tempfile(fileext = \".zip\")\n\ndownload.file(url = \"https://static-content.springer.com/esm/art%3A10.1038%2Fsrep00196/MediaObjects/41598_2011_BFsrep00196_MOESM2_ESM.zip\", destfile = s2_zip)\ndownload.file(url = \"https://static-content.springer.com/esm/art%3A10.1038%2Fsrep00196/MediaObjects/41598_2011_BFsrep00196_MOESM3_ESM.zip\", destfile = s3_zip)\n\nunzip(s2_zip, exdir = recipes_data_dir)\nunzip(s3_zip, exdir = recipes_data_dir)\n```\n:::\n\nThe recipes are in a horrendous format. It's not so bad that the first four lines are comments, that's easy to handle, but rows of the data do not have consistent lengths. The first recipe contains 6 items and the second has 17, which means the data's not rectangular and the standard importers aren't going to be that happy.\n\n::: {.cell}\n\n```{.r .cell-code}\nreadLines(file.path(recipes_data_dir, \"srep00196-s3.csv\")) %>%\n  head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"#\"                                                                                                                                         \n[2] \"# Flavor network and the principles of food pairing\"                                                                                       \n[3] \"# Yong-Yeol Ahn, Sebastian E. Ahnert, James P. Bagrow, and Albert-Laszlo Barabasi\"                                                         \n[4] \"# \"                                                                                                                                        \n[5] \"African,chicken,cinnamon,soy_sauce,onion,ginger\"                                                                                           \n[6] \"African,cane_molasses,ginger,cumin,garlic,tamarind,bread,coriander,vinegar,onion,beef,cayenne,parsley,wheat_bread,yogurt,vegetable_oil,egg\"\n```\n:::\n:::\n\nI really struggled to understand what to do about this, so I asked my first `R` question on StackOverflow, [\"Importing and analysing non-rectangular .csv files in R\"](https://stackoverflow.com/a/30016983/1659890). My question was asked back in 2015 [before the tidyverse was born](https://twitter.com/drob/status/748196885307920385), and so the best solution at the time was using `read.table`:\n\n::: {.cell}\n\n```{.r .cell-code}\nread.table(file.path(recipes_data_dir, \"srep00196-s3.csv\"), \n           sep = \",\", \n           as.is = TRUE, \n           fill = TRUE, \n           na.strings = \"\") %>% \n  head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       V1            V2       V3          V4       V5       V6       V7\n1 African       chicken cinnamon   soy_sauce    onion   ginger     <NA>\n2 African cane_molasses   ginger       cumin   garlic tamarind    bread\n3 African        butter   pepper       onion cardamom  cayenne   ginger\n4 African     olive_oil   pepper       wheat     beef    onion cardamom\n5 African         honey    wheat       yeast     <NA>     <NA>     <NA>\n6 African        tomato cilantro lemon_juice    onion  cayenne scallion\n              V8      V9      V10  V11     V12     V13         V14    V15\n1           <NA>    <NA>     <NA> <NA>    <NA>    <NA>        <NA>   <NA>\n2      coriander vinegar    onion beef cayenne parsley wheat_bread yogurt\n3 cottage_cheese  garlic brassica <NA>    <NA>    <NA>        <NA>   <NA>\n4          cumin  garlic     rice leek    <NA>    <NA>        <NA>   <NA>\n5           <NA>    <NA>     <NA> <NA>    <NA>    <NA>        <NA>   <NA>\n6           <NA>    <NA>     <NA> <NA>    <NA>    <NA>        <NA>   <NA>\n            V16  V17\n1          <NA> <NA>\n2 vegetable_oil  egg\n3          <NA> <NA>\n4          <NA> <NA>\n5          <NA> <NA>\n6          <NA> <NA>\n```\n:::\n:::\n\nAt the time I continued to analyse and visualise the data ready for my interview exercise, for which I also learned how to use GitHub! The outputs I used in my presentation are still available in my [RecipeVisualisations](https://github.com/charliejhadley/RecipeVisualisations) repo. It turns out on reflection that there were two bad things that I did at the time:\n\n- I didn't know enough R to have a reproducible workflow so have lost some of my tidying scripts\n- `read.table` uses a bad heuristic to decide how many columns there are in the data! The longest recipe is **not** 17 ingredients long.\n\nNow I'm much more proficient with R and have the wonderful `purrr` library to process these recipes into a `tibble` with the ingredients stored as a list:\n\n::: {.cell}\n\n```{.r .cell-code}\nrecipe_lists <- readLines(file.path(recipes_data_dir, \"srep00196-s3.csv\")) %>%\n  strsplit(\",\")\nrecipe_lists <- recipe_lists[5:length(recipe_lists)]\nrecipes_df <- tibble(\n  cuisine = map_chr(recipe_lists, 1),\n  ingredients = map(recipe_lists, tail, -1)\n)\nrecipes_df %>%\n  head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 2\n  cuisine ingredients\n  <chr>   <list>     \n1 African <chr [5]>  \n2 African <chr [16]> \n3 African <chr [9]>  \n4 African <chr [10]> \n5 African <chr [3]>  \n6 African <chr [6]>  \n```\n:::\n:::\n\nIt's now much easier to operate on these lists of ingredients by using `map*` functions within `mutate`, for instance I can create a column containing the number of ingredients. Now we discover the joint longest recipes contain a ridiculous **32 ingredients**. \n\n::: {.cell}\n\n```{.r .cell-code}\nrecipes_df %>%\n  mutate(n.ingredients = map_int(ingredients, length)) %>%\n  arrange(desc(n.ingredients))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 56,498 × 3\n   cuisine          ingredients n.ingredients\n   <chr>            <list>              <int>\n 1 EasternEuropean  <chr [32]>             32\n 2 SouthernEuropean <chr [32]>             32\n 3 NorthAmerican    <chr [30]>             30\n 4 NorthAmerican    <chr [29]>             29\n 5 NorthAmerican    <chr [29]>             29\n 6 NorthAmerican    <chr [29]>             29\n 7 EasternEuropean  <chr [28]>             28\n 8 NorthAmerican    <chr [28]>             28\n 9 NorthAmerican    <chr [27]>             27\n10 NorthAmerican    <chr [26]>             26\n# … with 56,488 more rows\n```\n:::\n:::\n\nWith our ingredients in a list column it's now also easy to filter recipes by specific ingredients:\n\n::: {.cell}\n\n```{.r .cell-code}\nrecipes_df %>%\n  filter(str_detect(ingredients, \"garlic\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 16,893 × 2\n   cuisine ingredients\n   <chr>   <list>     \n 1 African <chr [16]> \n 2 African <chr [9]>  \n 3 African <chr [10]> \n 4 African <chr [12]> \n 5 African <chr [11]> \n 6 African <chr [8]>  \n 7 African <chr [9]>  \n 8 African <chr [12]> \n 9 African <chr [15]> \n10 African <chr [10]> \n# … with 16,883 more rows\n```\n:::\n:::\n\nI'm going to come back to using this dataset in the future to explore graph theory and machine learning examples, but for now let's [finish like it's Summer 2017](https://eagereyes.org/blog/2017/joy-plots) with a ridgeline plot from the excellent `ggplot2` extension `ggridges`:\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(\"ggridges\")\nrecipes_df %>%\n  mutate(n.ingredients = map_int(ingredients, length)) %>%\n  group_by(cuisine) %>%\n  mutate(median.ingredients = median(n.ingredients)) %>%\n  ungroup() %>%\n  arrange(desc(median.ingredients)) %>%\n  mutate(cuisine = fct_reorder(cuisine, median.ingredients)) %>%\n  ggplot(aes(x = n.ingredients, y = cuisine)) + \n  geom_density_ridges(scale = 3) + \n  theme_ridges() +\n  xlab(\"Number of ingredients\") +\n  ggtitle(\"Comparison of ingredients per recipe by cuisine\",\n          subtitle = \"Data from doi:10.1038/srep00196\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/recipes-ingredients-ggridge-1.png){width=672}\n:::\n:::\n\nIn future whenever I want to work with this data I'll import it through the following script:\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(\"tidyverse\")\nrecipes_data_dir <- tempdir()\ns2_zip <- tempfile(fileext = \".zip\")\ns3_zip <- tempfile(fileext = \".zip\")\n\ndownload.file(url = \"https://static-content.springer.com/esm/art%3A10.1038%2Fsrep00196/MediaObjects/41598_2011_BFsrep00196_MOESM2_ESM.zip\", destfile = s2_zip)\ndownload.file(url = \"https://static-content.springer.com/esm/art%3A10.1038%2Fsrep00196/MediaObjects/41598_2011_BFsrep00196_MOESM3_ESM.zip\", destfile = s3_zip)\n\nunzip(s2_zip, exdir = recipes_data_dir)\nunzip(s3_zip, exdir = recipes_data_dir)\nrecipe_lists <- readLines(file.path(recipes_data_dir, \"srep00196-s3.csv\")) %>%\n  strsplit(\",\")\nrecipe_lists <- recipe_lists[5:length(recipe_lists)]\nrecipes_df <- tibble(\n  cuisine = map_chr(recipe_lists, 1),\n  ingredients = map(recipe_lists, tail, -1)\n)\n```\n:::\n\n\n[^1]: Frustratingly, these data sets are attached to the paper exclusively as supplementary materials, and so these are fragile links. Data should really have distinct DOI, modern journals like Springer Nature's [Scientific Data](www.nature.com/sdata/) do this.",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": null
  }
}